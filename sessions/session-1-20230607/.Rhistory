stat_compare_means(method="t.test")
penguins %>%
drop_na(speces, body_mass_g, sex) %>%
ggplot(aes(x=species, y=body_mass_g, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
ggplot(aes(x=species, y=body_mass_g, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
ggplot(aes(y=species, x=body_mass_g, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
ggplot(aes(x=body_mass_g, y=species, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
ggplot(aes(x=species, y=body_mass_g, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
ggplot() %>%
geom_col(aes(x=sex, y=body_mass_g))
penguins %>%
ggplot() +
geom_col(aes(x=sex, y=body_mass_g))
penguins %>%
ggplot() +
geom_col(aes(x=sex, y=body_mass_g), stat="mean")
penguins %>%
ggplot() +
geom_bar(aes(x=sex))
penguins %>%
ggplot() +
geom_col(aes(x=sex, y=body_mass_g), stat="mean")
penguins %>%
ggplot() +
geom_bar(aes(x=sex, y=body_mass_g), stat="mean")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
group_by(sex) %>%
summarize(avg_bm = mean(body_mass_g))
penguins %>%
drop_na(species, body_mass_g, sex) %>%
group_by(sex) %>%
summarize(avg_bm = mean(body_mass_g)) %>%
ggplot() + geom_col(aes(sex, avg_bm))
penguins %>%
drop_na(species, body_mass_g, sex) %>%
group_by(sex) %>%
summarize(avg_bm = mean(body_mass_g)) %>%
ggplot() + geom_bar(aes(sex, avg_bm), stat="identity")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
group_by(sex) %>%
summarize(avg_bm = mean(body_mass_g)) %>%
ggplot() + geom_bar(aes(sex, avg_bm))
penguins %>%
drop_na(species, body_mass_g, sex) %>%
ggplot(aes(x=species, y=body_mass_g, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
ggplot(aes(x=species, y=body_mass_g, fill=sex)) +
geom_col(position="dodge") +
stat_compare_means(method="t.test")
penguins %>%
ggplot() +
geom_bar(aes(x=sex, y=body_mass_g), stat="mean")
penguins %>%
drop_na(species, body_mass_g, sex) %>%
group_by(sex) %>%
summarize(avg_bm = mean(body_mass_g)) %>%
ggplot() + geom_col(aes(sex, avg_bm))
penguins %>%
drop_na(species, body_mass_g, sex) %>%
group_by(sex) %>%
summarize(avg_bm = mean(body_mass_g)) %>%
ggplot() + geom_bar(aes(sex, avg_bm),stat="identity")
library(tidyverse)
library(palmerpenguins)
penguins %>% filter(unique(species))
penguins %>% unique(species)
penguins %>% distinct(species)
penguins
valid_species <- data.frame(species = "Chinstrap")
penguins %>% semi_join(valid_species, by="species")
penguins %>% View()
penguins %>% View()
penguins %>% count(species)
valid_species <- data.frame(species = c("Chinstrap"))
penguins %>% semi_join(valid_species, by="species") %>% View()
penguins %>% count(year)
valid_records <- data.frame(year = c(2008, 2009))
penguins %>% semi_join(valid_records, by="year") %>% View()
penguins %>% semi_join(valid_records, by="year") %>% count(year)
penguins %>%
group_by(species) %>%
summarize(n_distinct(island))
# filter out species with too many islands:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count > 1)
# filter out species with too many islands:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1)
# get back to individual observations:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1) %>%
ungroup()
# get back to individual observations:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1) %>%
ungroup()
# get back to individual observations:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
ungroup() %>%
filter(island_count == 1)
# get back to individual observations:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
ungroup()
# count number of island values for each species:
penguins %>%
group_by(species) %>%
summarize(n_distinct(island))
# count number of island values for each species:
penguins %>%
group_by(species) %>%
summarize(n_distinct(island))
# filter out species with too many islands:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1)
# filter out species with too many islands:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1)
# get back to individual observations:
penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1) %>%
ungroup()
# get back to individual observations:
valid_species <- penguins %>%
group_by(species) %>%
summarize(island_count = n_distinct(island)) %>%
filter(island_count == 1) %>%
select(species)
View(valid_species)
penguins %>%
semi_join(valid_species, by="species")
for (filename in drug_filenames) {
print(filename)
}
drug_filenames <- c("aa", "bb")
for (filename in drug_filenames) {
print(filename)
}
library(palmerpenguins)
library(readr)    # write_csv
library(writexl)  # write_
library(readxl)
library(palmerpenguins)
library(readr)    # write_csv
library(writexl)  # write_xlsx
library(readxl)
data(penguins)  # make penguins an explicit object
write_csv(penguins, "penguins.csv")
write_xlsx(penguins, "penguins.xlsx")
saveRDS(penguins, "penguins.RDS")
penguins2 <- read_csv("penguins.csv")
penguins3 <- read_xlsx("penguins.xlsx")
penguins4 <- readRDS("penguins.RDS")
qprob(150, 10, )
qnorm(.9, mean=150, sd=10)
qnorm(.9, mean=150, sd=10)*10/5
pnorm(.9, mean=150, sd=10)
xbar <- 150
sd <- 10
n <- 25
error <- qnorm(.9)*sd/sqrt(n)
error
error <- qnorm(.95)*sd/sqrt(n)
error
x_bar <- 498
n <- 16
sd <- 95
25.8/sqrt(n)
25.8/sqrt(20)
library(infer)
dplyr::glimpse(gss)
hist(gss$hours)
library(tidyverse)
observed_statistic <- gss %>% specify(response = hours) %>% calculate(stat="mean")
null_dist_1_sample <- gss %>% specify(response=hours) %>% hypothesize(null="point", mu=40) %>% generate(reps=1000, type="bootstrap") %>% calculate(stat="mean")
null_dist_1_sample %>% visualize() + shade_p_value(observed_statistic, direction="two-sided")
t_test(x=gss, formula=hours~college, order=c("degree", "no degree"), alternative="two-sided")
12/5
12/10
mu <- 21
sigma <- 6.2
n <- 251
sigma/sqrt(n)
music <- c(60, 100, 95, 80, 67, 88, 76, 86, 90, 95, 91, 100)
nomusic <- c(55, 70, 90, 81, 67, 89, 34, 76, 94, 88, 100, 67, 93, 76, 89)
s_m <- sd(music)
s_nm <- sd(nomusic)
length(music)
df <- ( (s_m^2/length(music) + s_nm^2/length(nomusic)^2 )/( (s_m^2/length(music))^2/(s_nm-1) + (s_nm^2/length(nomusic))^2/(length(nomusic)-1) )
)
s1 <- s_m
s2 <- s_nm
n1 <- length(music)
n2 <- length(nomusic)
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
3.35/sqrt(26)
x_bar <- 460
s <- 40
n <- 30
#define variables for the test
m1 = 460
m2 = 500
s1 = 40
s2 = 40
n1 = 30
n2 = 30
## Null hypothesis
m0 = 460
#standard error
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
#t statistic
t <- (m1-m2-m0)/se
t
p_val <- round(2*pt(-abs(t),df),4)
p_val
p_val <- 2*pt(-abs(t),df)
p_val
#| echo: false
#| warning: false
insout <- read_csv("outreach-instruction-202205-202304.csv")
#| output: false
#| echo: false
library(tidyverse)
library(viridis)
#| echo: false
#| warning: false
insout <- read_csv("outreach-instruction-202205-202304.csv")
insout <- janitor::clean_names(insout)
insout <- insout %>% rename(event_name = 7, class_number = 8)
insout <- insout %>% mutate(orientation = as_factor(orientation))
insout <- insout %>% mutate(month = floor_date(as_date(word(event_date, 1)), unit="month"), .before=event_date)
insout <- insout %>%
mutate(ldw = event_date >= "2023-02-10" & event_date <= "2023-02-18")
# insout %>% filter(event_date >= "2023-02-10" & event_date <= "2023-02-18")
survey_f <- read_csv("DSS Fall 2022 Workshop Evaluation Form_April 26, 2023_17.33.csv") %>% janitor::clean_names()
survey_f <- survey_f %>%
select(clarity = "q25_7", difficulty = "q26_1") %>%
filter(row_number() > 3)
survey_f <- survey_f %>% drop_na()
survey_s <- read_csv("DSS Spring 2023 Workshop Evaluation Form_April 26, 2023_17.18.csv") %>% janitor::clean_names()
survey_s <- survey_s %>%
select(clarity="q25_7", difficulty="q26_1") %>%
filter(row_number() > 2 & !is.na(clarity))
surveys <- bind_rows(survey_f, survey_s)
surveys <- surveys %>%
mutate(clarity = as.numeric(clarity),
difficulty = as.numeric(difficulty))
insout %>%
mutate(orientation = fct_relevel(orientation, c("skills", "information", "hosted"))) %>%
group_by(orientation, ldw) %>%
summarize(par_count = sum(number_of_participants)) %>%
ggplot(aes(x=par_count, y=orientation, fill=!ldw)) +
geom_bar(stat="identity") +
scale_fill_discrete(type=c("#cc4778", "#0d0887"), name="Event setting", labels=rev(c("Semesterly series", "Love Data Week 2023"))) +
scale_y_discrete(limits=rev, labels=rev(c("Skills workshop", "Informational talk", "Hosted talk or workshop"))) +
theme_minimal() +
labs(x = "Participant count",
y = "Event type",
title = "Instruction and outreach events by Dominic Bordelon,\nMay 2022–April 2023") +
guides(fill = guide_legend(reverse = TRUE)) +
theme(legend.position="bottom")
insout %>%
group_by(orientation) %>%
summarize(`Event count` = n(),
Participants = sum(number_of_participants),
`Avg. Participants` = round(mean(number_of_participants), 1)) %>%
knitr::kable()
skills <- insout %>% filter(orientation=="skills")
hosted <- insout %>% filter(orientation=="hosted")
info <- insout %>% filter(orientation=="information")
#| output: false
#| echo: false
library(tidyverse)
library(viridis)
#| echo: false
#| warning: false
insout <- read_csv("outreach-instruction-202205-202304.csv")
insout <- janitor::clean_names(insout)
insout <- insout %>% rename(event_name = 7, class_number = 8)
insout <- insout %>% mutate(orientation = as_factor(orientation))
insout <- insout %>% mutate(month = floor_date(as_date(word(event_date, 1)), unit="month"), .before=event_date)
insout <- insout %>%
mutate(ldw = event_date >= "2023-02-10" & event_date <= "2023-02-18")
# insout %>% filter(event_date >= "2023-02-10" & event_date <= "2023-02-18")
survey_f <- read_csv("DSS Fall 2022 Workshop Evaluation Form_April 26, 2023_17.33.csv") %>% janitor::clean_names()
survey_f <- survey_f %>%
select(clarity = "q25_7", difficulty = "q26_1") %>%
filter(row_number() > 3)
survey_f <- survey_f %>% drop_na()
survey_s <- read_csv("DSS Spring 2023 Workshop Evaluation Form_April 26, 2023_17.18.csv") %>% janitor::clean_names()
survey_s <- survey_s %>%
select(clarity="q25_7", difficulty="q26_1") %>%
filter(row_number() > 2 & !is.na(clarity))
surveys <- bind_rows(survey_f, survey_s)
surveys <- surveys %>%
mutate(clarity = as.numeric(clarity),
difficulty = as.numeric(difficulty))
insout %>%
mutate(orientation = fct_relevel(orientation, c("skills", "information", "hosted"))) %>%
group_by(orientation, ldw) %>%
summarize(par_count = sum(number_of_participants)) %>%
ggplot(aes(x=par_count, y=orientation, fill=!ldw)) +
geom_bar(stat="identity") +
scale_fill_discrete(type=c("#cc4778", "#0d0887"), name="Event setting", labels=rev(c("Semesterly series", "Love Data Week 2023"))) +
scale_y_discrete(limits=rev, labels=rev(c("Skills workshop", "Informational talk", "Hosted talk or workshop"))) +
theme_minimal() +
labs(x = "Participant count",
y = "Event type",
title = "Instruction and outreach events by Dominic Bordelon,\nMay 2022–April 2023") +
guides(fill = guide_legend(reverse = TRUE)) +
theme(legend.position="bottom")
insout %>%
group_by(orientation) %>%
summarize(`Event count` = n(),
Participants = sum(number_of_participants),
`Avg. Participants` = round(mean(number_of_participants), 1)) %>%
knitr::kable()
skills <- insout %>% filter(orientation=="skills")
hosted <- insout %>% filter(orientation=="hosted")
info <- insout %>% filter(orientation=="information")
#| echo: false
#| warning: false
# cumulative
consultations %>%
arrange(date) %>%
select(date) %>%
mutate(month = floor_date(date, unit="month")) %>%
group_by(month) %>%
summarize(month_count = n()) %>%
mutate(month_cum = cumsum(month_count)) %>%
ggplot(aes(x=month, y=month_count)) +
geom_bar(stat="identity") +
geom_point(aes(y=month_cum)) +
geom_line(aes(y=month_cum)) +
theme_minimal() +
labs(x="Month",
y="Consultations count",
title="Cumulative consultations by Dominic Bordelon,\nMay 2022–April 2023")
#| echo: false
#| warning: false
consultations <- read_csv("consultations_202205-202304.csv")
consultations <- janitor::clean_names(consultations)
consultations <- consultations %>% filter(referral_consult == "Consultation")
# identify drop-in
consultations <- consultations %>%
mutate(all_notes = paste(details, question, answer, notes), .before=details) %>%
mutate(dropin = str_detect(c(all_notes), "[D|d]rop"), .before=all_notes)
#| echo: false
#| warning: false
# cumulative
consultations %>%
arrange(date) %>%
select(date) %>%
mutate(month = floor_date(date, unit="month")) %>%
group_by(month) %>%
summarize(month_count = n()) %>%
mutate(month_cum = cumsum(month_count)) %>%
ggplot(aes(x=month, y=month_count)) +
geom_bar(stat="identity") +
geom_point(aes(y=month_cum)) +
geom_line(aes(y=month_cum)) +
theme_minimal() +
labs(x="Month",
y="Consultations count",
title="Cumulative consultations by Dominic Bordelon,\nMay 2022–April 2023")
# monthly
consultations %>%
arrange(date) %>%
select(date, dropin) %>%
mutate(month = floor_date(date, unit="month")) %>%
group_by(month, dropin) %>%
summarize(month_count = n()) %>%
mutate(month_cum = cumsum(month_count)) %>%
ggplot(aes(x=month, y=month_count, fill=dropin)) +
geom_bar(stat="identity") +
scale_fill_viridis(discrete=TRUE,
name="Format",
labels=c("Consultation","R Drop-In Hour")) +
theme_minimal() +
labs(x="Month",
y="Consultations count",
title="Monthly consultations by Dominic Bordelon,\nMay 2022–April 2023")
295/30
mean(c(19.83, 20.14, 19.28, 19.75, 19.39))
mean(c(19.83, 20.14, 19.28, 19.75, 19.39, 19.86, 19.02, 19.71))
sd(c(19.83, 20.14, 19.28, 19.75, 19.39, 19.86, 19.02, 19.71))/sqrt(8)
mean(c(3.7424, 5.2717, 6.786, 5.6959))
sd(c(3.7424, 5.2717, 6.786, 5.6959))/sqrt(4)
mean(c(4.676, 7.267, 10.86))
mean(c(4.676, 7.300, 10.86))
sd(c(4.676, 7.300, 10.86))/sqrt(3)
(5-3.7424)/5
(3.7424-5)/5
(4.676-5)/5
mean(c(3.7424,5.2717,6.786,5.6959))
sd(c(3.7424,5.2717,6.786,5.6959))
sd(c(3.7424,5.2717,6.786,5.6959))/sqrt(4)
mean(c(4.676, 7.300,10.86))
sd(c(4.676, 7.300,10.86))
sd(c(4.676, 7.300,10.86))/sqrt(3)
sd(c(4.676, 7.300,10.86))/sqrt(4)
sd(c(4.676, 7.300,10.86))/sqrt(3)
sd(19.29, 20.50, 19.29)
sd(c(19.29, 20.50, 19.29))
sd(c(19.29, 20.50, 19.29))/sqrt(3)
.9843/6.375e-4
.9843/(6.375e-4)
.9843/.0006375
mean(c(1, 2, 3))
sd(c(1, 2, 3))/sqrt(3)
quarto::quarto_version()
1+1
seq(1,100, by=1)
sqrt(16)
c(1, 2, 3, 4, 5)
mean(1, 2, 3, 4, 5)
mean(c(1, 2, 3, 4, 5))
mean(c(1), 2, 3, 4, 5)
1+1
# patient weights in lbs:
c(264, 356, 155, 280, 175)
# freezer temps in deg. C:
c(-23.22, -22.90, -23.19, -22.87, -22.94, -23.19)
# patient weights in lbs:
c(264, 356, 155, 280, 175)
# freezer temps in deg. C:
c(-23.22, -22.90, -23.19, -22.87, -22.94, -23.19)
# patient weights in lbs:
c(264, 356, 155, 280, 175)
# freezer temps in deg. C:
c(-23.22, -22.90, -23.19, -22.87, -22.94, -23.19)
sqrt(c(2-3*7/9))
# freezer temps in deg. C:
c(-23.22, -22.90, -23.19, -22.87, -22.94, -23.19)
sd(c(2.34, 3.56, 9.72))
setwd("C:/Users/djb190/OneDrive - University of Pittsburgh/training/202306_pstp/sessions/session-1-20230607")
foo <- "a"
rm(foo)
foo <- "a"
c(264, 356, 155, 280, 175)
c(264, 356, 155, 280, 175) * .454
c(264, 356, 155, 280, 175) * 0.454
c(264, 356, 155, 280, 175) * 0.454
# patient weights in lbs:
c(264, 356, 155, 280, 175)
c(264, 356, 155, 280, 175) * 0.454
# freezer temps in deg. C:
c(-23.22, -22.90, -23.19, -22.87, -22.94, -23.19)
# your code here
signif((mean(c(1, 99, 100)), 2)
# your code here
signif(mean(c(1, 99, 100)), 2)
# your code here
signif(mean(c(1, 99, 100)), digits=2)
?signif
# your code here
signif(mean(c(1, 99, 100)))
# your code here
signif(mean(c(1, 99, 100)), digits=2)
install.packages("tidyverse")
library(tidyverse)
library(readr)
read_csv("data/indo_rct.csv")
indo_rct <- read_csv("data/indo_rct.csv")
View(indo_rct)
"hello"+5
View(indo_rct)
indo_rct$age
write_csv(indo_rct, "indo_changed.csv")
