---
title: "Summer R"
subtitle: "Session 5: Joins, factors, and pivoting"
author: "Dominic Bordelon, Research Data Librarian, ULS"
format: 
  revealjs:
    self-contained: true
    footer: "Summer R 5: Joins, factors, and pivoting"
    logo: "images/ULS_logo1.png"
    execute:
      echo: true
editor: visual
---

```{r}
#| output: false
#| echo: false
library(tidyverse)
library(medicaldata)
```

## Agenda

[Joins]

[Factors]

[Pivoting]

[Inference and modeling]

## Introducing forcats, tidyr, and tidymodels {.smaller}

::: columns
::: {.column width="70%"}
We've used dplyr for many data frame operations. In our last session, we're trying out three new packages:

-   **forcats**: working with factors (categorical variables); tidyverse
-   **tidyr**: restructure (pivot) a data frame; tidyverse
-   **tidymodels**: inference and modeling
:::

::: {.column width="30%"}
![](images/forcats-logo.png){fig-align="center" width="87"}

![](images/tidyr-logo.png){fig-align="center" width="87"}

![](images/tidymodels-logo.png){fig-align="center" width="87"}
:::
:::

------------------------------------------------------------------------

```{r}
#| echo: true
#| output: false
#| warning: false

library(tidyverse)
# includes dplyr, forcats, tidyr
library(medicaldata)

# install.packages("tidymodels")
library(tidymodels)
```

# Joins

## Relational data and table joins {.smaller}

-   Much of the world's data lives in *relational database management systems* (RDBMSes), or simply "relational databases"
-   Sometimes you might work with one of these directly; other times you might receive CSV files which originated in a RDBMS
-   "Relational" == Table A has a relationship to Table B, via column X which appears in both tables ("foreign key relationship")
-   Why relational?
    -   One big table gets to be unmanageable, but we also don't want to duplicate info in the multiple places that we need it
    -   Often-repeated values (e.g., a drug name) can be more efficiently stored/retrieved if they are replaced by a number, which points to the human-readable name.

*Joining* synthesizes a new a table from two or more parent tables.

## Relationship types {.smaller}

-   **One-to-one relationships**: one row in Table A corresponds to one row in Table B
-   **One-to-many relationships**: "lookup" function; controlled vocabulary; Table B describes categories that are referenced in Table A
-   **Many-to-many relationships**: there are many subjects (Table A), and many genetic markers (Table B); a patient may have an unspecified number of markers and vice versa, a relationship described in Table C

It can be helpful to have these relationships in mind when thinking about different ways we might want to join tables together.

## Types of joins {.smaller}

Join type asks, "if I have unpaired rows when I join Tables A and B, what do I do with those rows?"

-   Full join: keep all rows from both tables, filling `NA` as needed
-   Inner join: keep only rows that appear in *both* tables
-   Left join: inner join + keep all of the rows from the *left* table, filling `NA` as needed
-   Right join: inner join + keep all of the rows from the *right* table, filling `NA` as needed
-   Filtering joins: filter rows of Table A based on presence/absence of the row's ID in Table B

Each of the above joins might produce a different number of rows.

------------------------------------------------------------------------

```{r}
#| warning: false

lg_sample <- read_csv("data/lg_sample.csv")
asa_status <- read_csv("data/asa_status.csv")
```

Consider these two tables:

::: columns
::: {.column width="50%"}
```{r}
#| echo: true

# 6-row sample of licorice_gargle

lg_sample %>% 
  select(1:3)
```
:::

::: {.column width="50%"}
```{r}
#| echo: true

# listing of ASA statuses

asa_status
```
:::
:::

```{r}
#| eval: false
#| echo: false

# data(licorice_gargle)
# 
# asa_status <- licorice_gargle %>% 
#   select(asa_status_id = preOp_asa) %>% 
#   distinct() %>% 
#   arrange(asa_status_id) %>% 
#   mutate(asa_status = case_when(
#     asa_status_id == 1 ~ "a normal healthy patient",
#     asa_status_id == 2 ~ "a patient with mild systemic disease",
#     asa_status_id == 3 ~ "a patient with severe systemic disease",
#     asa_status_id == 4 ~ "UNUSED CATEGORY"
#   ))
# write_csv(asa_status, "data/asa_status.csv")
# lg_sample <- licorice_gargle %>% 
#   slice_sample(n=6)
# write_csv(lg_sample, "data/lg_sample.csv")
# lg_sample <- read_csv("data/lg_sample.csv")
```

## `full_join()`: combine all data

```{r}
lg_sample %>%
  select(1:4) %>% 
  full_join(y = asa_status, by = join_by(preOp_asa == asa_status_id))
```

Note 7 rows: 5 with matches in both tables; one Table A patient with no pre-op ASA status reported; and one Table B unused category.

## `inner_join()`: keep only rows from both tables

```{r}
lg_sample %>%
  select(1:4) %>% 
  inner_join(y = asa_status, by = join_by(preOp_asa == asa_status_id))
```

Now we have only the five rows that appear in both tables.

## `left_join()`: keep rows from x

```{r}
lg_sample %>%
  select(1:4) %>% 
  left_join(y = asa_status, by = join_by(preOp_asa == asa_status_id))
```

Now we have increased to 6 rows, because we kept all of the left table, including the patient with no pre-op ASA status reported.

## `right_join()`: keep rows from y

```{r}
lg_sample %>%
  select(1:4) %>% 
  right_join(y = asa_status, by = join_by(preOp_asa == asa_status_id))
```

6 rows again, but this time we have dropped the nonreporting patient, and we see instead the unused category.

## `semi_join()`, `anti_join()`: filter x vs. y {.smaller}

Filtering joins decide which rows to keep from x, based on the presence (or absence) of the value in y

Example: you applied inclusion criteria to get a list of patient ID's to include in analysis, and now you would like to filter just those patients' records into a data frame.

```{r}
inclusion_ids <- tibble(subject_id = c(9134, 663, 5408))

covid_testing %>% 
  semi_join(y = inclusion_ids, by = join_by(subject_id))
```

# Factors

## Factors

-   Factors are special vectors for categorical variables
-   A factor has one or more **levels** of accepted values
-   Values are integers with a human-readable label
-   Levels may be ordered or unordered

```{r}
c("A", "B", "C", "B", "A", "B") %>% summary()

as_factor(c("A", "B", "C", "B", "A", "B")) %>% summary()
```

## Jobs involving factors {.smaller}

Typical things you'll need to do with factors:

-   Convert character vector into factor: `as_factor()`
-   Change the label associated with a level: `fct_recode()`
-   Collapse two or more levels into one level (e.g., "Other"): `fct_collapse()`
-   Change factor's order of levels: several functions

```{r}
my_fct <- as_factor(c("A", "B", "C", "B", "A", "B"))

my_fct
my_fct %>% fct_recode(beta = "B")
my_fct %>% fct_collapse(Other = c("A", "B"))
my_fct %>% fct_infreq()
```

------------------------------------------------------------------------

![[Artwork by \@allison_horst](https://twitter.com/allison_horst)](images/fct_infreq.png){fig-alt="Header text: \"forcats::fct_infreq() - reorder factor levels by # of observations in each level (default: largest n = first level). Below, and illustration of monsters working together to reorder a data set based on the most commonly observed animals. Additional text: \"See also: fct_inorder to reorder by order of appearance, fct_reorder to reorder by another variable, and fct_relevel to manually reorder.\" Learn more about working with factors in the forcats package." fig-align="center"}

# ICA 5.1: Joins and factors

# Pivoting

## Pivoting: what and why {.smaller}

-   To "pivot" tabular data means to restructure part of it in terms of column and row definition
-   Example: a variable described by *one column per year* of interest
    -   But ggplot expects all values to be in the same column
    -   Solution: all values into a new `value` column, and each year into a new `year` column
    -   $n \mathrm{\ columns} \rightarrow 2 \mathrm{\ columns}$
-   The goal is often "tidy data": one observation per row, one variable per column

------------------------------------------------------------------------

![[Artwork by \@allison_horst](https://twitter.com/allison_horst)](images/tidy-data1.jpg){fig-alt="Stylized text providing an overview of Tidy Data. The top reads “Tidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.” On the left reads “In tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.” There is an example table on the lower right with columns ‘id’, ‘name’ and ‘color’ with observations for different cats, illustrating tidy data structure." fig-align="center"}

------------------------------------------------------------------------

![[Artwork by \@allison_horst](https://twitter.com/allison_horst)](images/tidy-data2.jpg){fig-alt="On the left is a happy cute fuzzy monster holding a rectangular data frame with a tool that fits the data frame shape. On the workbench behind the monster are other data frames of similar rectangular shape, and neatly arranged tools that also look like they would fit those data frames. The workbench looks uncluttered and tidy. The text above the tidy workbench reads “When working with tidy data, we can use the same tools in similar ways for different datasets…” On the right is a cute monster looking very frustrated, using duct tape and other tools to haphazardly tie data tables together, each in a different way. The monster is in front of a messy, cluttered workbench. The text above the frustrated monster reads “...but working with untidy data often means reinventing the wheel with one-time approaches that are hard to iterate or reuse.”" fig-align="center"}

## `pivot_longer()` {.smaller}

-   For when you need reduce the number of columns, making the table *longer* with more rows
-   Or: when multiple *observations* are compressed into a single row
-   Note required arguments (given in example below)
-   Example: annual teen birth counts by state, one column for each year (2013-19); source: [CDC](https://www.cdc.gov/nchs/data-visualization/teen-births/)
    -   `cols =` the year columns (`` `2013`:`2019` ``)
    -   `names_to =`[new]{.underline} column where you want the years recorded (`year`)
    -   `values_to =`[new]{.underline} column where you want the values recorded (`births`)

```{r}
#| echo: false
#| output: false

births <- read_csv("../data/NCHS_-_U.S._and_State_Trends_on_Teen_Births.csv")
teen_births <- births %>% 
  filter(Year > 2012) %>% 
  group_by(State, Year) %>% 
  summarize(births=sum(`State Births`)) %>% 
  pivot_wider(names_from = Year, values_from = births)
```

------------------------------------------------------------------------

##  {.smaller}

::: columns
::: {.column width="50%"}
Before pivoting

```{r}
#| echo: true
teen_births %>% print(width=58)
```

Data source: [CDC](https://www.cdc.gov/nchs/data-visualization/teen-births/)
:::

::: {.column width="50%"}
After pivoting longer

```{r}
#| echo: true
teen_births %>% 
  pivot_longer(cols = `2013`:`2019`,
               names_to = "year", 
               values_to = "births")
```
:::
:::

## `pivot_wider()`

-   For when you need to increase the number of columns, making the table *wider* with fewer rows
-   Rare that you will need to use this for tidying; usually for generating a summary/comparison table, or for [transforming to the format expected by another tool](https://tidyr.tidyverse.org/articles/pivot.html#capture-recapture-data)
-   Note required arguments `names_from`, `values_from`

# ICA 5.2: Pivoting

# Inference and modeling {data-link="Inference and modeling"}

## Checking for normality: histogram + theoretical {.smaller}

The ggplot2 `stat_function()` layer allows you to plot various statistical functions (such as a theoretical distribution). Note that for the two layers to be compatible, we transform the histogram's `y` to density. `dnorm()` is the base R function for the Normal distribution.

```{r}
#| echo: true
#| eval: false
mu <- mean(polyps$number12m, na.rm=TRUE)
sigma <- sd(polyps$number12m, na.rm=TRUE)

polyps %>% 
  drop_na(number12m) %>% 
  ggplot() +
  geom_histogram(aes(x=number12m, y=after_stat(density)), binwidth = 3) +
  stat_function(fun=dnorm, geom="line", color="blue", linewidth=1.5,
                args=list(mean=mu, sd=sigma))
```

------------------------------------------------------------------------

```{r}
#| echo: true
mu <- mean(polyps$number12m, na.rm=TRUE)
sigma <- sd(polyps$number12m, na.rm=TRUE)

polyps %>% 
  drop_na(number12m) %>% 
  ggplot() +
  geom_histogram(aes(x=number12m, y=after_stat(density)), binwidth = 3) +
  stat_function(fun=dnorm, geom="line", color="blue", linewidth=1.5,
                args=list(mean=mu, sd=sigma))
```

## Checking for normality: Q-Q plot

```{r}
#| echo: true
num12m_qqp <- polyps %>% 
  drop_na(number12m) %>% 
  ggplot(aes(sample=number12m)) +
  geom_qq_line(color="blue") +
  geom_qq()
num12m_qqp
```

## Sidebar: plot annotations

`annotate()` is an additional ggplot layer you can add to plots:

```{r}
num12m_qqp <- num12m_qqp +
  annotate(geom="label", x=-1.5, y=25, 
           label="Distribution lacks\nNormality below -1σ")
num12m_qqp
```

## Sidebar: saving plots

`ggplot2::ggsave()` allows us to save plot objects in a variety of formats and parameters. Here are example calls:

```{r}
#| eval: false
#| echo: true

# scalable vector graphics (SVG) format:
ggsave(filename="num12m-qq.svg", plot=num12m_qqp)

# 500 x 400 px PNG file, 100dpi:
ggsave(filename="num12m-qq.png", plot=num12m_qqp,
       width=500, height=400, units="px", dpi=100)

# 4 in. x 6 in. PDF, 300dpi:
ggsave(filename="num12m-qq.pdf", plot=num12m_qqp,
       width=4, height=6, units="in")
# note that this plot will be in a portrait format

```

## Inference and modeling - the base R way {.smaller}

-   A variety of functions are available depending on the test / probability distribution / regression you need
-   These functions usually expect [vectors]{.underline} as input; usually produce some printable object (`summary()` also usable)
-   Student's t-test: `t.test()`
-   Chi-squared test: `chisq.test()` (note: expects a [matrix]{.underline} for 2-way)
-   Linear model: `lm()` with `predict()`

These functions can be compatible with tidyverse work (but not `%>%` )

------------------------------------------------------------------------

##  {.smaller}

Are mean 12-month counts significantly different between sulindac (treatment) and placebo groups?

```{r}
#| echo: true

sulindac12m <- polyps %>% 
  filter(treatment == "sulindac") %>% 
  pull(number12m)
sulindac12m

placebo12m <- polyps %>% 
  filter(treatment == "placebo") %>% 
  pull(number12m)
placebo12m

t.test(sulindac12m, placebo12m)
```

------------------------------------------------------------------------

##  {.smaller}

Is there a relationship between baseline and 12-month counts?

```{r}
#| echo: true
polyps_model <- lm(number12m ~ baseline, data=polyps)
polyps_model

plot(polyps$baseline, polyps$number12m)
abline(polyps_model, col="blue")
```

What 12-month count does this model predict for a baseline of 50? of 100?

```{r}
#| echo: true
new_baseline <- tibble(
  baseline = c(50, 100)
)
predict(polyps_model, newdata=new_baseline)
```

## Inference and modeling - the tidymodels way {.smaller}

-   Specifically, the {infer} and {parsnip} packages
-   New verbs for the tidyverse pipeline: (or you can use wrappers like `t_test()`)
    -   `specify()` variable/relationship of interest
    -   `hypothesize()` the null hypothesis
    -   `generate()` (or simulate if theoretical) the null distribution
    -   `calculate()` a test statistic like `Chisq, F, t,` or `z`
-   Good vignettes for getting started: [Getting to Know infer](https://infer.tidymodels.org/articles/infer.html), [Introduction to parsnip](https://parsnip.tidymodels.org/articles/parsnip.html)

------------------------------------------------------------------------

##  {.smaller}

Are mean 12-month counts significantly different between sulindac (treatment) and placebo groups?

```{r}
#| echo: true

# infer::t_test()

polyps %>% 
  t_test(response = number12m,
         explanatory = treatment)

```

------------------------------------------------------------------------

##  {.smaller}

Is there a relationship between baseline and 12-month counts?

```{r}
#| echo: true
# parsnip::linear_reg()

polyps_model <- linear_reg() %>% 
  set_engine("lm") %>% 
  fit(number12m ~ baseline, data = polyps)
polyps_model
```

What 12-month count does this model predict for a baseline of 50? of 100?

```{r}
new_baseline <- tibble(
  baseline = c(50, 100)
)
predict(polyps_model, new_baseline)
```

## Plotting a model (without `geom_smooth`) {.smaller}

Run `predict()` on a data frame of your explanatory values. Then bind the predicted column back with the original data frame and plot the predictions with their own `geom_line()`.

```{r}
#| warning: false
#| echo: true
baseline_df <- polyps %>%
  select(baseline)

predicted_df <- predict(polyps_model, new_data = baseline_df) %>% 
  rename(predicted_12m = ".pred") %>% 
  mutate(predicted_12m = round(predicted_12m, 1))
predicted_df
```

------------------------------------------------------------------------

```{r}
#| echo: true
polyps %>% 
  bind_cols(predicted_df) %>% 
  ggplot() +
  geom_point(aes(x=baseline, y=number12m)) +
  geom_line(aes(x=baseline, y=predicted_12m),
            color="blue")
```

# ICA 5.3: Inference and modeling

# Wrap up

## Conclusion

We learned about:

-   joining tables to combine data
-   working with factors for categorical variables
-   pivoting a data frame to restructure it
-   what inference and modeling look like in R

## Potential next directions

-   Exploring more of [tidymodels](https://www.tidymodels.org/learn/)
-   [Computational Genomics with R](http://compgenomr.github.io/book/) (free ebook)
-   ...or one of many other topics in the [Big Book of R](https://www.bigbookofr.com/) directory

Always feel free to reach out! [dbordelon\@pitt.edu](mailto:dbordelon@pitt.edu)
